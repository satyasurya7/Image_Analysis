{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee005e5",
   "metadata": {
    "papermill": {
     "duration": 0.029402,
     "end_time": "2022-02-08T03:01:33.390940",
     "exception": false,
     "start_time": "2022-02-08T03:01:33.361538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "This is image data of Natural Scenes around the world.\n",
    "\n",
    "This Data contains around 25k images of size 150x150 distributed under 6 categories.\n",
    "- 'buildings' -> 0,\n",
    "- 'forest' -> 1,\n",
    "- 'glacier' -> 2,\n",
    "- 'mountain' -> 3,\n",
    "- 'sea' -> 4,\n",
    "- 'street' -> 5 \n",
    "\n",
    "The Train, Test and Prediction data is separated in each zip files. There are around 14k images in Train, 3k in Test and 7k in Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29bdaa",
   "metadata": {
    "papermill": {
     "duration": 0.027952,
     "end_time": "2022-02-08T03:01:33.447463",
     "exception": false,
     "start_time": "2022-02-08T03:01:33.419511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importing necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6c81af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-08T03:01:33.508121Z",
     "iopub.status.busy": "2022-02-08T03:01:33.506875Z",
     "iopub.status.idle": "2022-02-08T03:01:34.931062Z",
     "shell.execute_reply": "2022-02-08T03:01:34.930182Z",
     "shell.execute_reply.started": "2022-02-01T17:23:57.241663Z"
    },
    "papermill": {
     "duration": 1.455569,
     "end_time": "2022-02-08T03:01:34.931262",
     "exception": false,
     "start_time": "2022-02-08T03:01:33.475693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5184/2950709174.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb0f8e8",
   "metadata": {
    "papermill": {
     "duration": 0.027858,
     "end_time": "2022-02-08T03:01:34.987724",
     "exception": false,
     "start_time": "2022-02-08T03:01:34.959866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Exploring the dataset\n",
    "\n",
    "We will normalize the image tensors by subtracting the mean and dividing by the standard deviation across each channel. As a result, the mean of the data across each channel is 0, and standard deviation is 1. Normalizing the data prevents the values from any one channel from disproportionately affecting the losses and gradients while training, simply by having a higher or wider range of values that others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf7a4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:01:35.047173Z",
     "iopub.status.busy": "2022-02-08T03:01:35.046543Z",
     "iopub.status.idle": "2022-02-08T03:02:22.604876Z",
     "shell.execute_reply": "2022-02-08T03:02:22.605465Z",
     "shell.execute_reply.started": "2022-02-01T17:23:59.001512Z"
    },
    "papermill": {
     "duration": 47.589888,
     "end_time": "2022-02-08T03:02:22.605705",
     "exception": false,
     "start_time": "2022-02-08T03:01:35.015817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4300, 0.4573, 0.4537]), tensor([0.2482, 0.2467, 0.2806]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ImageFolder(\"D:\\Image_Analysis\\Image_Analysis\\Image Data\\seg_train\", transform = tt.Compose([\n",
    "    tt.Resize(64),\n",
    "    tt.RandomCrop(64),\n",
    "    tt.ToTensor(),\n",
    "]))\n",
    "train_dl = DataLoader(train, 64, shuffle=True, num_workers=3, pin_memory=True)\n",
    "\n",
    "def get_mean_std(dl):\n",
    "    \n",
    "    sum_, squared_sum, batches = 0,0,0\n",
    "    for data, _ in dl:\n",
    "        sum_ += torch.mean(data, dim = ([0,2,3]))\n",
    "        squared_sum += torch.mean(data**2, dim = ([0,2,3]))\n",
    "        batches += 1\n",
    "        \n",
    "    mean = sum_/batches\n",
    "    std = (squared_sum/batches - mean**2)**0.5\n",
    "    return mean,std\n",
    "\n",
    "mean, std = get_mean_std(train_dl)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28296abe",
   "metadata": {
    "papermill": {
     "duration": 0.029549,
     "end_time": "2022-02-08T03:02:22.664010",
     "exception": false,
     "start_time": "2022-02-08T03:02:22.634461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will apply randomly chosen transformations while loading images from the training dataset. Specifically, we will pad each image by 4 pixels, and then take a random crop of size 64 x 64 pixels, and then flip the image horizontally with a 50% probability. Since the transformation will be applied randomly and dynamically each time a particular image is loaded, the model sees slightly different images in each epoch of training, which allows it generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a55e688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:22.724437Z",
     "iopub.status.busy": "2022-02-08T03:02:22.723468Z",
     "iopub.status.idle": "2022-02-08T03:02:22.730036Z",
     "shell.execute_reply": "2022-02-08T03:02:22.730635Z",
     "shell.execute_reply.started": "2022-02-01T17:24:40.484443Z"
    },
    "papermill": {
     "duration": 0.038634,
     "end_time": "2022-02-08T03:02:22.730812",
     "exception": false,
     "start_time": "2022-02-08T03:02:22.692178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats = ((0.4951, 0.4982, 0.4979), (0.2482, 0.2467, 0.2807))\n",
    "train_transform = tt.Compose([\n",
    "    tt.Resize(64),\n",
    "    tt.RandomCrop(64),\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats,inplace=True)\n",
    "])\n",
    "\n",
    "test_transform = tt.Compose([\n",
    "    tt.Resize(64),\n",
    "    tt.RandomCrop(64),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(*stats,inplace=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f02631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:22.791095Z",
     "iopub.status.busy": "2022-02-08T03:02:22.790109Z",
     "iopub.status.idle": "2022-02-08T03:02:25.903765Z",
     "shell.execute_reply": "2022-02-08T03:02:25.904309Z",
     "shell.execute_reply.started": "2022-02-01T17:24:40.492027Z"
    },
    "papermill": {
     "duration": 3.145449,
     "end_time": "2022-02-08T03:02:25.904481",
     "exception": false,
     "start_time": "2022-02-08T03:02:22.759032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/intel-image-classification/seg_train/seg_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10960/3825016052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/intel-image-classification/seg_train/seg_train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/intel-image-classification/seg_test/seg_test\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\env\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     ):\n\u001b[1;32m--> 310\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\env\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\env\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\env\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \"\"\"\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/intel-image-classification/seg_train/seg_train'"
     ]
    }
   ],
   "source": [
    "train = ImageFolder(\"../input/intel-image-classification/seg_train/seg_train\", transform = train_transform)\n",
    "test = ImageFolder(\"../input/intel-image-classification/seg_test/seg_test\",transform = test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb46fdc",
   "metadata": {
    "papermill": {
     "duration": 0.028278,
     "end_time": "2022-02-08T03:02:25.961104",
     "exception": false,
     "start_time": "2022-02-08T03:02:25.932826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will split our dataset into two parts:\n",
    "- train_ds: for training the data.\n",
    "- valid_ds: for testing our model accuracy.(this will tell you how well your model will perform on dataset which model has never seen)\n",
    "\n",
    "`Note: `  we will not use test data as the part of validation, this data will actually determine your model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dfa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:26.022606Z",
     "iopub.status.busy": "2022-02-08T03:02:26.021433Z",
     "iopub.status.idle": "2022-02-08T03:02:26.026550Z",
     "shell.execute_reply": "2022-02-08T03:02:26.027176Z",
     "shell.execute_reply.started": "2022-02-01T17:24:43.247435Z"
    },
    "papermill": {
     "duration": 0.037633,
     "end_time": "2022-02-08T03:02:26.027380",
     "exception": false,
     "start_time": "2022-02-08T03:02:25.989747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153a87b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:26.089685Z",
     "iopub.status.busy": "2022-02-08T03:02:26.088713Z",
     "iopub.status.idle": "2022-02-08T03:02:26.096704Z",
     "shell.execute_reply": "2022-02-08T03:02:26.097293Z",
     "shell.execute_reply.started": "2022-02-01T17:24:43.254084Z"
    },
    "papermill": {
     "duration": 0.040723,
     "end_time": "2022-02-08T03:02:26.097467",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.056744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = int(len(train) * 0.2)\n",
    "train_size = len(train) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd460f5",
   "metadata": {
    "papermill": {
     "duration": 0.028408,
     "end_time": "2022-02-08T03:02:26.155447",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.127039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we can create data loaders for retrieving images in batches. We'll use a relatively large batch size of 128 to utlize a larger portion of the GPU RAM. You can try reducing the batch size & restarting the kernel if you face an \"out of memory\" error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d1924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:26.215957Z",
     "iopub.status.busy": "2022-02-08T03:02:26.215345Z",
     "iopub.status.idle": "2022-02-08T03:02:26.222335Z",
     "shell.execute_reply": "2022-02-08T03:02:26.222858Z",
     "shell.execute_reply.started": "2022-02-01T17:24:43.268633Z"
    },
    "papermill": {
     "duration": 0.038919,
     "end_time": "2022-02-08T03:02:26.223029",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.184110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# PyTorch data loaders\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)\n",
    "test_dl = DataLoader(test, batch_size*2, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64396c8",
   "metadata": {
    "papermill": {
     "duration": 0.028196,
     "end_time": "2022-02-08T03:02:26.279921",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.251725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at some sample images from the training dataloader. To display the images, we'll need to denormalize the pixels values to bring them back into the range (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91fd63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:26.340158Z",
     "iopub.status.busy": "2022-02-08T03:02:26.339511Z",
     "iopub.status.idle": "2022-02-08T03:02:26.346420Z",
     "shell.execute_reply": "2022-02-08T03:02:26.346873Z",
     "shell.execute_reply.started": "2022-02-01T17:24:43.278475Z"
    },
    "papermill": {
     "duration": 0.038547,
     "end_time": "2022-02-08T03:02:26.347043",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.308496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def denormalize(images, means, stds):\n",
    "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
    "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
    "    return images * stds + means\n",
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        denorm_images = denormalize(images, *stats)\n",
    "        ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0,1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8277e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:26.411254Z",
     "iopub.status.busy": "2022-02-08T03:02:26.410353Z",
     "iopub.status.idle": "2022-02-08T03:02:27.592037Z",
     "shell.execute_reply": "2022-02-08T03:02:27.592721Z",
     "shell.execute_reply.started": "2022-02-01T17:24:43.289316Z"
    },
    "papermill": {
     "duration": 1.217265,
     "end_time": "2022-02-08T03:02:27.592923",
     "exception": false,
     "start_time": "2022-02-08T03:02:26.375658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811a5a6",
   "metadata": {
    "papermill": {
     "duration": 0.054164,
     "end_time": "2022-02-08T03:02:27.700242",
     "exception": false,
     "start_time": "2022-02-08T03:02:27.646078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utility function and classes\n",
    "\n",
    "We will define few function and classes to move data into gpu, which will boost the training time to 10 times faster even more from cpu\n",
    "`Note:`You need to on the gpu accelerator. In the \"Settings\" section of the sidebar, select \"GPU\" from the \"Accelerator\" dropdown. Use the button on the top-right to open the sidebar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f98856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:27.810427Z",
     "iopub.status.busy": "2022-02-08T03:02:27.809676Z",
     "iopub.status.idle": "2022-02-08T03:02:27.818310Z",
     "shell.execute_reply": "2022-02-08T03:02:27.818836Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.530029Z"
    },
    "papermill": {
     "duration": 0.065588,
     "end_time": "2022-02-08T03:02:27.819006",
     "exception": false,
     "start_time": "2022-02-08T03:02:27.753418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cf82a",
   "metadata": {
    "papermill": {
     "duration": 0.053798,
     "end_time": "2022-02-08T03:02:27.926415",
     "exception": false,
     "start_time": "2022-02-08T03:02:27.872617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`ImageClassificationBase` is the base class, which calculates the losses and keep track of every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8334a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.056537Z",
     "iopub.status.busy": "2022-02-08T03:02:28.055799Z",
     "iopub.status.idle": "2022-02-08T03:02:28.066348Z",
     "shell.execute_reply": "2022-02-08T03:02:28.066860Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.544481Z"
    },
    "papermill": {
     "duration": 0.073792,
     "end_time": "2022-02-08T03:02:28.067030",
     "exception": false,
     "start_time": "2022-02-08T03:02:27.993238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4cdd4",
   "metadata": {
    "papermill": {
     "duration": 0.053588,
     "end_time": "2022-02-08T03:02:28.173649",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.120061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Moving our data into gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31e32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.284349Z",
     "iopub.status.busy": "2022-02-08T03:02:28.282085Z",
     "iopub.status.idle": "2022-02-08T03:02:28.287067Z",
     "shell.execute_reply": "2022-02-08T03:02:28.287580Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.560145Z"
    },
    "papermill": {
     "duration": 0.061173,
     "end_time": "2022-02-08T03:02:28.287758",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.226585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fa471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.398913Z",
     "iopub.status.busy": "2022-02-08T03:02:28.398281Z",
     "iopub.status.idle": "2022-02-08T03:02:28.400571Z",
     "shell.execute_reply": "2022-02-08T03:02:28.401086Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.574394Z"
    },
    "papermill": {
     "duration": 0.060475,
     "end_time": "2022-02-08T03:02:28.401275",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.340800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44895d61",
   "metadata": {
    "papermill": {
     "duration": 0.053477,
     "end_time": "2022-02-08T03:02:28.508745",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.455268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building the model\n",
    "\n",
    "We will extend `ImageClassificationBase` to develop the `ResNet9` model which consist of `Residual Blocks` after every two CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267a4f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.627766Z",
     "iopub.status.busy": "2022-02-08T03:02:28.617797Z",
     "iopub.status.idle": "2022-02-08T03:02:28.630727Z",
     "shell.execute_reply": "2022-02-08T03:02:28.630103Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.584019Z"
    },
    "papermill": {
     "duration": 0.068948,
     "end_time": "2022-02-08T03:02:28.630883",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.561935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace=True)]\n",
    "    if pool: layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.conv2 = conv_block(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        self.conv3 = conv_block(128, 256, pool=True)\n",
    "        self.conv4 = conv_block(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9a091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.740204Z",
     "iopub.status.busy": "2022-02-08T03:02:28.739178Z",
     "iopub.status.idle": "2022-02-08T03:02:28.744582Z",
     "shell.execute_reply": "2022-02-08T03:02:28.745185Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.597404Z"
    },
    "papermill": {
     "duration": 0.061719,
     "end_time": "2022-02-08T03:02:28.745378",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.683659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_of_classes = len(train.classes)\n",
    "no_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a691b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:28.855315Z",
     "iopub.status.busy": "2022-02-08T03:02:28.854269Z",
     "iopub.status.idle": "2022-02-08T03:02:28.923902Z",
     "shell.execute_reply": "2022-02-08T03:02:28.923270Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.611488Z"
    },
    "papermill": {
     "duration": 0.125448,
     "end_time": "2022-02-08T03:02:28.924040",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.798592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = to_device(ResNet9(3, no_of_classes), device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69218b",
   "metadata": {
    "papermill": {
     "duration": 0.053439,
     "end_time": "2022-02-08T03:02:29.031264",
     "exception": false,
     "start_time": "2022-02-08T03:02:28.977825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add8c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:29.147879Z",
     "iopub.status.busy": "2022-02-08T03:02:29.146868Z",
     "iopub.status.idle": "2022-02-08T03:02:29.154413Z",
     "shell.execute_reply": "2022-02-08T03:02:29.154872Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.685506Z"
    },
    "papermill": {
     "duration": 0.06987,
     "end_time": "2022-02-08T03:02:29.155048",
     "exception": false,
     "start_time": "2022-02-08T03:02:29.085178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    # Set up cutom optimizer with weight decay\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # Set up one-cycle learning rate scheduler\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
    "                                                steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Record & update learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e1557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:02:29.265628Z",
     "iopub.status.busy": "2022-02-08T03:02:29.264940Z",
     "iopub.status.idle": "2022-02-08T03:04:16.811324Z",
     "shell.execute_reply": "2022-02-08T03:04:16.811842Z",
     "shell.execute_reply.started": "2022-02-01T17:24:44.698481Z"
    },
    "papermill": {
     "duration": 107.603168,
     "end_time": "2022-02-08T03:04:16.812033",
     "exception": false,
     "start_time": "2022-02-08T03:02:29.208865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = [evaluate(model, valid_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87dbc3",
   "metadata": {
    "papermill": {
     "duration": 0.054089,
     "end_time": "2022-02-08T03:04:16.920853",
     "exception": false,
     "start_time": "2022-02-08T03:04:16.866764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initially, with random weight, we the accuracy of 16.79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebcc201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:04:17.035948Z",
     "iopub.status.busy": "2022-02-08T03:04:17.035303Z",
     "iopub.status.idle": "2022-02-08T03:04:17.036748Z",
     "shell.execute_reply": "2022-02-08T03:04:17.037285Z",
     "shell.execute_reply.started": "2022-02-01T17:24:53.928745Z"
    },
    "papermill": {
     "duration": 0.061752,
     "end_time": "2022-02-08T03:04:17.037448",
     "exception": false,
     "start_time": "2022-02-08T03:04:16.975696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbf7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T03:04:17.148822Z",
     "iopub.status.busy": "2022-02-08T03:04:17.148134Z",
     "iopub.status.idle": "2022-02-08T07:26:51.554728Z",
     "shell.execute_reply": "2022-02-08T07:26:51.556910Z",
     "shell.execute_reply.started": "2022-02-01T17:24:53.935526Z"
    },
    "papermill": {
     "duration": 15754.466193,
     "end_time": "2022-02-08T07:26:51.558122",
     "exception": false,
     "start_time": "2022-02-08T03:04:17.091929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8c172",
   "metadata": {
    "papermill": {
     "duration": 0.058829,
     "end_time": "2022-02-08T07:26:51.676544",
     "exception": false,
     "start_time": "2022-02-08T07:26:51.617715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Within 5 mins, we have achieved the accuracy of 90%, Now lets check where our model stands in test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b1490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T07:26:51.847154Z",
     "iopub.status.busy": "2022-02-08T07:26:51.846238Z",
     "iopub.status.idle": "2022-02-08T07:26:51.849718Z",
     "shell.execute_reply": "2022-02-08T07:26:51.849091Z",
     "shell.execute_reply.started": "2022-02-01T17:29:54.625758Z"
    },
    "papermill": {
     "duration": 0.11415,
     "end_time": "2022-02-08T07:26:51.849889",
     "exception": false,
     "start_time": "2022-02-08T07:26:51.735739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c34ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T07:26:51.973897Z",
     "iopub.status.busy": "2022-02-08T07:26:51.973111Z",
     "iopub.status.idle": "2022-02-08T07:26:52.289989Z",
     "shell.execute_reply": "2022-02-08T07:26:52.290587Z",
     "shell.execute_reply.started": "2022-02-01T17:29:54.633692Z"
    },
    "papermill": {
     "duration": 0.380522,
     "end_time": "2022-02-08T07:26:52.290770",
     "exception": false,
     "start_time": "2022-02-08T07:26:51.910248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec15f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T07:26:52.420443Z",
     "iopub.status.busy": "2022-02-08T07:26:52.419579Z",
     "iopub.status.idle": "2022-02-08T07:26:52.422693Z",
     "shell.execute_reply": "2022-02-08T07:26:52.422031Z",
     "shell.execute_reply.started": "2022-02-01T17:29:54.883411Z"
    },
    "papermill": {
     "duration": 0.070551,
     "end_time": "2022-02-08T07:26:52.422860",
     "exception": false,
     "start_time": "2022-02-08T07:26:52.352309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85279d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T07:26:52.551517Z",
     "iopub.status.busy": "2022-02-08T07:26:52.550818Z",
     "iopub.status.idle": "2022-02-08T07:26:52.756913Z",
     "shell.execute_reply": "2022-02-08T07:26:52.757401Z",
     "shell.execute_reply.started": "2022-02-01T17:29:54.889979Z"
    },
    "papermill": {
     "duration": 0.274356,
     "end_time": "2022-02-08T07:26:52.757590",
     "exception": false,
     "start_time": "2022-02-08T07:26:52.483234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_lrs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34343b33",
   "metadata": {
    "papermill": {
     "duration": 0.060496,
     "end_time": "2022-02-08T07:26:52.878594",
     "exception": false,
     "start_time": "2022-02-08T07:26:52.818098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e5407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T07:26:53.005444Z",
     "iopub.status.busy": "2022-02-08T07:26:53.004756Z",
     "iopub.status.idle": "2022-02-08T07:28:24.896842Z",
     "shell.execute_reply": "2022-02-08T07:28:24.897398Z",
     "shell.execute_reply.started": "2022-02-01T17:29:55.088209Z"
    },
    "papermill": {
     "duration": 91.957557,
     "end_time": "2022-02-08T07:28:24.897588",
     "exception": false,
     "start_time": "2022-02-08T07:26:52.940031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(test_dl, device)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0d06b",
   "metadata": {
    "papermill": {
     "duration": 0.060411,
     "end_time": "2022-02-08T07:28:25.018356",
     "exception": false,
     "start_time": "2022-02-08T07:28:24.957945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Our model has achieved the accuracy of `89.92%` of accuracy!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16023.152987,
   "end_time": "2022-02-08T07:28:26.563442",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-08T03:01:23.410455",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
